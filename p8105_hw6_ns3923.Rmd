---
title: "p8105_hw6_ns3923"
output: github_document
---

**Set up necessary libraries**
```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(p8105.datasets)
library(modelr)
```

## Problem 1: The Washington Post - homicides 

**1) Import dataset**
```{r P1_import, message = FALSE}
homicide_df = read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()

homicide_df
```

**2) Cleaning and tidying data**

* Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. 
* Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO (don’t report victim race), and omit Tulsa, AL (a data entry mistake). 
* Limit those for whom victim_race is white or black, and victim_age is numeric.

```{r P1_clean, message = FALSE, warning=FALSE}
homicide_df = homicide_df |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved   = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) |> 
  
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |> 
  drop_na(victim_age, victim_sex, victim_race)

##Check
homicide_df 
```

**3) Logistic regression for Baltimore, MD**

* Use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. 

```{r P1_baltimore, message = FALSE}
baltimore_df = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_fit = 
  baltimore_df |> 
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data   = _,
    family = binomial()
  )

baltimore_or = 
  baltimore_fit |> 
  tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  mutate(term = "Male vs Female (ref)") |> 
  select(term, estimate, conf.low, conf.high)

baltimore_or |> 
  knitr::kable(digits = 3)
```

**Table 1: the estimated OR and 95% CI of resolved vs unresolved of male compared to female victims**

**Explanation:** In Baltimore, MD, after adjusting for victim age and race, homicides with male victims have lower odds of being resolved compared to homicides with female victims (adjusted OR = 0.426; 95% CI: 0.324, 0.558). Because the confidence interval does not include 1, there is significant evidence that cases involving male victims are less likely to be solved.

**4) Adjusted OR and CI for solving homicides comparing male to female victims**

```{r P1_OR, message=FALSE, warning=FALSE}
city_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(
      data,
      ~ glm(resolved ~ victim_age + victim_sex + victim_race,
            data = ., family = binomial())
    ),
    tidy_res = map(
      models,
      ~ tidy(., conf.int = TRUE, exponentiate = TRUE)
    )
  ) |> 
  select(city_state, tidy_res) |> 
  unnest(tidy_res) |> 
  filter(term == "victim_sexMale") |> 
  rename(
    or       = estimate,
    or_lower = conf.low,
    or_upper = conf.high
  )

city_results |> 
  arrange(or) |> 
  select(city_state, or, or_lower, or_upper) |> 
  mutate(
    or       = round(or, 3),
    or_lower = round(or_lower, 3),
    or_upper = round(or_upper, 3)
  ) |> 
  knitr::kable(
    col.names = c(
      "City",
      "Adjusted OR (Male vs Female)",
      "Lower 95% CI",
      "Upper 95% CI"
    )
  )
```

**Table 2: The adjusted OR (Male vs Female) and 95% CI for solving homicides**

**5) Create a plot shows the estimated ORs and CIs for each city**

```{r P1_plot, message=FALSE, fig.height=8}
city_results |> 
  mutate(city_state = fct_reorder(city_state, or)) |> 
  ggplot(aes(x = city_state, y = or)) +
  geom_point(color = "red") +
  geom_errorbar(aes(ymin = or_lower, ymax = or_upper), width = 0.5) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Figure 1: Adjusted ORs for solving homicides (Male vs Female)",
    x = "City",
    y = "Adjusted OR"
  ) +
  theme_minimal()
```

**Interpretation:** Most cities have odds ratios below 1, meaning homicides involving male victims are less likely to be solved than those involving female victims, after adjusting for victim age and race. Only a few cities, such as Albuquerque, NM, Stockton, CA, and Fresno, CA, have odds ratios above 1. Still, their confidence intervals are wide, so the results are uncertain, and we cannot be sure whether solving rates are truly higher among male than female victims. These uncertain exceptions may reflect a smaller population or more variable case patterns in those cities. The lowest odds ratios are in New York, NY, Baton Rouge, LA, and Omaha, NE. These cities show a much lower chance of solving cases involving male victims. 

## Problem 2: Central Park weather data

**1) Import data**
```{r P2_import, message=FALSE}
data("weather_df")

set.seed(123)
```

We’ll focus on a simple linear regression with `tmax` as the response with `tmin` and `prcp` as the predictors, and are interested in the distribution of two quantities estimated from these data:

* Estimated R-squared
* Ratio of estimated beta_1/beta_2 (β1/β2)

**2) Clean dataset**

```{r P2_clean, message=FALSE}
weather_df_clean = weather_df |>
  drop_na(tmax, tmin, prcp)

n_obs = nrow(weather_df_clean)
```

**3) Create 5,000 bootstrap samples and fit the model in each sample**

```{r P2_bootstrap, message=FALSE}
weather_bootstrap = weather_df_clean |> 
  bootstrap(5000, id = "strap_id") |> 
  mutate(
    model = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance = map(model, glance),
    tidy = map(model, tidy)
  )
```

**4) The estimated r-squared (r^2) and beta_1 and beta_2 (β1/β2)**

```{r P2_extract, message=FALSE}
boot_results = weather_bootstrap |> 
  transmute(
    strap_id,
    r_sq = map_dbl(glance, "r.squared"),
    beta_1 = map_dbl(
      tidy,
      ~ .x |> 
        filter(term == "tmin") |> 
        pull(estimate)
    ),
    beta_2 = map_dbl(
      tidy,
      ~ .x |> 
        filter(term == "prcp") |> 
        pull(estimate)
    ),
    beta_ratio = beta_1 / beta_2
  )

boot_results

```

**5) Plot the distribution of the estimates r-squared and beta1/beta2 (β1/β2)**

```{r P2_plot, message=FALSE}
boot_results |> 
  ggplot(aes(x = r_sq)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "white") +
  labs(
    title = "Figure 2: Bootstrap distribution of estimated R-squared",
    x = expression(hat(r)^2),
    y = "Count"
  ) +
  theme_minimal()

boot_results |> 
  ggplot(aes(x = beta_ratio)) +
  geom_histogram(bins = 30, fill = "orange", color = "white") +
  labs(
    title = "Figure 3: Bootstrap distribution of β1/β2",
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count"
  ) +
  theme_minimal()

```

**Explanation:** The bootstrap distribution of the estimated R-squared is centered around 0.94, indicating the model consistently explains most of the variation in `tmax` across samples. In addition, the distribution of the ratio β1/β2 is entirely negative and more spread out. This happens because `tmin` has a strong positive effect on `tmax`, while
`prcp` has a small negative effect. Overall, this shows that the effect of `tmin` is very stable, but the small size of the `prcp` coefficient leads to more variability in the ratio.

**6) Identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for R-squared and β1/β2**

```{r P2_CI, message=FALSE}
boot_ci =
  boot_results |>
  summarize(
    r_sq_lower  = quantile(r_sq, 0.025),
    r_sq_upper  = quantile(r_sq, 0.975),
    ratio_lower = quantile(beta_ratio, 0.025),
    ratio_upper = quantile(beta_ratio, 0.975)
  )

boot_ci |> 
  knitr::kable(digits = 3,
               col.names = c(
                 "R² lower",
                 "R² upper",
                 "β₁/β₂ lower",
                 "β₁/β₂ upper"
               ))
```
**Table 3: The lower and upper bound of R-squared and β1/β2**

**Explanation:** The 2.5% and 97.5% bootstrap quantiles for R-squared are 0.934 and 0.947, respectively. The 95% confidence interval of R-squared is (0.934, 0.947). This narrow interval shows that the model is stable and consistently explains more than 93% of the variation in `tmax`. For the ratio β1/β2, the 2.5% and 97.5% quantiles are -277.17 and -125.71, resulting in a 95% confidence interval of (–277.17 to –125.71), which is entirely negative. This indicates that `tmin` has a strong positive effect on `tmax`, while `prcp` has a small negative effect across samples.


## Problem 3: Birthweight

**1) Import dataset**
```{r P3_import, message = FALSE, warning=FALSE}
bw_df = read_csv("./data/birthweight.csv") |> 
  janitor::clean_names()

bw_df |> glimpse()
```

**2) Clean dataset**

* Convert baby's sex (`babysex`) and presence of malformation status (`malform`) to factors with descriptive labels.
* Convert maternal (`mrace`) and father's race (`frace`) as categorical variables. 
* Check for missing values across all variables.

```{r P3_clean, message=FALSE, warning=FALSE}
bw_df =
  bw_df |>
  mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    malform = factor(malform, labels = c("absent", "present")),
    mrace   = factor(mrace),
    frace   = factor(frace)
  )

bw_df |> summarize(across(everything(), ~ sum(is.na(.))))
```
**Check:** There is no missing data. So, the full dataset was used in subsequent analyses without additional cleaning or imputation.

**3) Proposed regression model**

Based on biological and clinical factors known to influence fetal growth and birthweight, I selected the following variables for the proposed regression model:

* `bhead`: baby’s head circumference at birth (centimeters)
* `blength`: baby’s length at birth (centimeters)
* `gaweeks`: gestational age in weeks
* `wtgain`: mother’s weight gain during pregnancy (pounds)
* `smoken`: average number of cigarettes smoked per day during pregnancy
* `momage`: mother’s age at delivery (years)

These variables reflect established determinants of fetal growth in obstetric and pediatric research. The model was fit using linear regression with birthweight (`bwt`) as the outcome.

```{r P3_proposedreg, message=FALSE}
bw_regfit = bw_df |>
  lm(
    bwt ~ bhead + blength + gaweeks + wtgain + smoken + momage,
    data = _
  )

bw_regfit |> tidy()

#model residuals against fitted value
bw_resid_df = bw_df |>
  add_predictions(bw_regfit) |>
  add_residuals(bw_regfit)

bw_resid_df |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3, color = "skyblue") +
  geom_smooth(se = FALSE, color = "red") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Figure 4: Residuals vs Fitted Values for Proposed Birthweight Model",
    x = "Fitted birthweight (grams)",
    y = "Residuals"
  ) +
  theme_minimal()
```

**Explanation:** From the plot, the residuals are centered around the zero line across the range of fitted birthweights, but the red trend line shows a slight curved pattern, especially at lower fitted values. This suggests that the linearity assumption is mostly reasonable, although the model may miss some mild non-linear structure. The spread of the residuals increases slightly at higher fitted values, but there is no strong evidence of heteroscedasticity or major violations of model assumptions. Overall, the residual plot suggests that the model fits the data adequately, with only minor deviations from ideal linearity.

**4) Compare the proposed model to two others:**

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these 

_Model 1: The proposed regression model_
```{r P3_comparedmodel1, message=FALSE}
model_1 = lm(bwt ~ bhead + blength + gaweeks + wtgain + smoken + momage, data = bw_df)
```

_Model 2: Main effect only (length of birth and gestational age)_
```{r P3_comparedmodel2, message=FALSE}
model_2 = lm(bwt ~ blength + gaweeks, data = bw_df)
```

_Model 3: Head circumference, length, sex, and all interactions (2-way and 3 -way interactions)_
```{r P3_comparedmodel3, message=FALSE}
model_3 = lm(bwt ~ bhead * blength * babysex, data = bw_df)
```

Make this comparison in terms of the cross-validated prediction error by using `crossv_mc` and functions in purrr as appropriate.

```{r P3_comparedmodels, message=FALSE}
set.seed(123)

cv_df = 
  crossv_mc(bw_df, n = 100)

cv_results =
  cv_df |> 
  mutate(
    mod_A = map(train, ~ lm(bwt ~ bhead + blength + gaweeks + wtgain + smoken + momage, data = .x)),
    mod_B = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    mod_C = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
    
    rmse_A = map2_dbl(mod_A, test, ~ rmse(model = .x, data = .y)),
    rmse_B = map2_dbl(mod_B, test, ~ rmse(model = .x, data = .y)),
    rmse_C = map2_dbl(mod_C, test, ~ rmse(model = .x, data = .y))
  )

cv_results |>
  summarize(
    rmse_A = mean(rmse_A),
    rmse_B = mean(rmse_B),
    rmse_C = mean(rmse_C)
  ) |> 
  knitr::kable(digits = 2,
  col.names = c("Proposed model",
              "Main effect only",
              "2- and 3-way interactions of head x length x sex"
                ))

```
**Table 4: Root Mean Squared Error (RMSE) showing the average size of the prediction error between the model-predicted birthweight and the true birthweight**

**Explanation:** The main-effects model performs the worst, with an RMSE of 330.71 grams, suggesting that relying on these two main predictors alone does not capture enough variation in birthweight. The interaction model performs better than the main-effects model but slightly worse than the proposed model (RMSE = 288.38 grams). In contrast, the proposed model has the lowest average cross-validated RMSE at 282.38 grams. This indicates that it provides the most accurate birthweight predictions among the three models.
