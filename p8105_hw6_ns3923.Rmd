---
title: "p8105_hw6_ns3923"
output: github_document
---

**Set up necessary libraries**
```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(p8105.datasets) #for problem 2
```

## Problem 1: The Washington Post - homicides 

**Import dataset**
```{r P1_import, message = FALSE}
homicide_df = read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()

homicide_df
```

**Cleaning and tidying data**

* Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. 
* Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO (don’t report victim race), and omit Tulsa, AL (a data entry mistake). 
* Limit those for whom victim_race is white or black, and victim_age is numeric.

```{r P1_clean, message = FALSE, warning=FALSE}
homicide_df = homicide_df |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved   = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) |> 
  
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |> 
  drop_na(victim_age, victim_sex, victim_race)

##Check
homicide_df 
```

**Logistic regression for Baltimore, MD**

* Use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. 

```{r P1_baltimore, message = FALSE}
baltimore_df = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_fit = 
  baltimore_df |> 
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data   = _,
    family = binomial()
  )

baltimore_or = 
  baltimore_fit |> 
  tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  mutate(term = "Male vs Female (ref)") |> 
  select(term, estimate, conf.low, conf.high)

baltimore_or |> 
  knitr::kable(digits = 3)
```

**Adjusted OR and CI for solving homicides comparing male to female victims**

```{r P1_OR, message=FALSE}
city_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(
      data,
      ~ glm(resolved ~ victim_age + victim_sex + victim_race,
            data = ., family = binomial())
    ),
    tidy_res = map(
      models,
      ~ tidy(., conf.int = TRUE, exponentiate = TRUE)
    )
  ) |> 
  select(city_state, tidy_res) |> 
  unnest(tidy_res) |> 
  filter(term == "victim_sexMale") |> 
  rename(
    or       = estimate,
    or_lower = conf.low,
    or_upper = conf.high
  )

city_results |> 
  arrange(or) |> 
  select(city_state, or, or_lower, or_upper) |> 
  mutate(
    or       = round(or, 3),
    or_lower = round(or_lower, 3),
    or_upper = round(or_upper, 3)
  ) |> 
  knitr::kable(
    col.names = c(
      "City",
      "Adjusted OR (Male vs Female)",
      "Lower 95% CI",
      "Upper 95% CI"
    )
  )
```

**Create a plot shows the estimated ORs and CIs for each city**

```{r P1_plot, message=FALSE, fig.height=8}
city_results |> 
  mutate(city_state = fct_reorder(city_state, or)) |> 
  ggplot(aes(x = city_state, y = or)) +
  geom_point(color = "red") +
  geom_errorbar(aes(ymin = or_lower, ymax = or_upper), width = 0.5) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Figure 1: Adjusted ORs for solving homicides (Male vs Female)",
    x = "City",
    y = "Adjusted OR"
  ) +
  theme_minimal()
```

**Interpretation:** Most cities have odds ratios below 1, meaning homicides involving male victims are less likely to be solved than those involving female victims, after adjusting for victim age and race. Only a few cities, such as Albuquerque, NM, Stockton, CA, and Fresno, CA, have odds ratios above 1. Still, their confidence intervals are wide, so the results are uncertain, and we cannot be sure whether solving rates are truly higher among male than female victims. These uncertain exceptions may reflect a smaller population or more variable case patterns in those cities. The lowest odds ratios are in New York, NY, Baton Rouge, LA, and Omaha, NE. These cities show a much lower chance of solving cases involving male victims. 

## Problem 2: Central Park weather data

**Import data**
```{r P2_import, message=FALSE}
data("weather_df")
```


The boostrap is helpful when you’d like to perform inference for a parameter / value / summary that doesn’t have an easy-to-write-down distribution in the usual repeated sampling framework. We’ll focus on a simple linear regression with tmax as the response with tmin and prcp as the predictors, and are interested in the distribution of two quantities estimated from these data:

r^2
β^1β^2
Use 5000 bootstrap samples and, for each bootstrap sample, produce estimates of these two quantities. Plot the distribution of your estimates, and describe these in words. Using the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r^2
 and β^1β^2
.

Note: broom::glance() is helpful for extracting r^2
 from a fitted regression, and broom::tidy() (with some additional wrangling) should help in computing β^1β^2


