p8105_hw6_ns3923
================

**Set up necessary libraries**

``` r
library(tidyverse)
library(broom)
library(p8105.datasets) #for problem 2
```

## Problem 1: The Washington Post - homicides

**Import dataset**

``` r
homicide_df = read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()

homicide_df
```

    ## # A tibble: 52,179 × 12
    ##    uid        reported_date victim_last  victim_first victim_race victim_age
    ##    <chr>              <dbl> <chr>        <chr>        <chr>       <chr>     
    ##  1 Alb-000001      20100504 GARCIA       JUAN         Hispanic    78        
    ##  2 Alb-000002      20100216 MONTOYA      CAMERON      Hispanic    17        
    ##  3 Alb-000003      20100601 SATTERFIELD  VIVIANA      White       15        
    ##  4 Alb-000004      20100101 MENDIOLA     CARLOS       Hispanic    32        
    ##  5 Alb-000005      20100102 MULA         VIVIAN       White       72        
    ##  6 Alb-000006      20100126 BOOK         GERALDINE    White       91        
    ##  7 Alb-000007      20100127 MALDONADO    DAVID        Hispanic    52        
    ##  8 Alb-000008      20100127 MALDONADO    CONNIE       Hispanic    52        
    ##  9 Alb-000009      20100130 MARTIN-LEYVA GUSTAVO      White       56        
    ## 10 Alb-000010      20100210 HERRERA      ISRAEL       Hispanic    43        
    ## # ℹ 52,169 more rows
    ## # ℹ 6 more variables: victim_sex <chr>, city <chr>, state <chr>, lat <dbl>,
    ## #   lon <dbl>, disposition <chr>

**Cleaning and tidying data**

- Create a city_state variable (e.g. “Baltimore, MD”), and a binary
  variable indicating whether the homicide is solved.
- Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO (don’t report
  victim race), and omit Tulsa, AL (a data entry mistake).
- Limit those for whom victim_race is white or black, and victim_age is
  numeric.

``` r
homicide_df = homicide_df |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolved   = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) |> 
  
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |> 
  drop_na(victim_age, victim_sex, victim_race)

##Check
homicide_df 
```

    ## # A tibble: 39,403 × 14
    ##    uid        reported_date victim_last  victim_first victim_race victim_age
    ##    <chr>              <dbl> <chr>        <chr>        <chr>            <dbl>
    ##  1 Alb-000003      20100601 SATTERFIELD  VIVIANA      White               15
    ##  2 Alb-000005      20100102 MULA         VIVIAN       White               72
    ##  3 Alb-000006      20100126 BOOK         GERALDINE    White               91
    ##  4 Alb-000009      20100130 MARTIN-LEYVA GUSTAVO      White               56
    ##  5 Alb-000016      20100308 GRAY         STEFANIA     White               43
    ##  6 Alb-000018      20100323 DAVID        LARRY        White               52
    ##  7 Alb-000019      20100402 BRITO        ELIZABETH    White               22
    ##  8 Alb-000021      20100423 KING         TEVION       Black               15
    ##  9 Alb-000022      20100423 BOYKIN       CEDRIC       Black               25
    ## 10 Alb-000023      20100518 BARRAGAN     MIGUEL       White               20
    ## # ℹ 39,393 more rows
    ## # ℹ 8 more variables: victim_sex <chr>, city <chr>, state <chr>, lat <dbl>,
    ## #   lon <dbl>, disposition <chr>, city_state <chr>, resolved <dbl>

**Logistic regression for Baltimore, MD**

- Use the glm function to fit a logistic regression with resolved vs
  unresolved as the outcome and victim age, sex and race as predictors.

``` r
baltimore_df = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_fit = 
  baltimore_df |> 
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data   = _,
    family = binomial()
  )

baltimore_or = 
  baltimore_fit |> 
  tidy(conf.int = TRUE, exponentiate = TRUE) |> 
  filter(term == "victim_sexMale") |> 
  mutate(term = "Male vs Female (ref)") |> 
  select(term, estimate, conf.low, conf.high)

baltimore_or |> 
  knitr::kable(digits = 3)
```

| term                 | estimate | conf.low | conf.high |
|:---------------------|---------:|---------:|----------:|
| Male vs Female (ref) |    0.426 |    0.324 |     0.558 |

**Adjusted OR and CI for solving homicides comparing male to female
victims**

``` r
city_results = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(
      data,
      ~ glm(resolved ~ victim_age + victim_sex + victim_race,
            data = ., family = binomial())
    ),
    tidy_res = map(
      models,
      ~ tidy(., conf.int = TRUE, exponentiate = TRUE)
    )
  ) |> 
  select(city_state, tidy_res) |> 
  unnest(tidy_res) |> 
  filter(term == "victim_sexMale") |> 
  rename(
    or       = estimate,
    or_lower = conf.low,
    or_upper = conf.high
  )
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `tidy_res = map(models, ~tidy(., conf.int = TRUE, exponentiate =
    ##   TRUE))`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

``` r
city_results |> 
  arrange(or) |> 
  select(city_state, or, or_lower, or_upper) |> 
  mutate(
    or       = round(or, 3),
    or_lower = round(or_lower, 3),
    or_upper = round(or_upper, 3)
  ) |> 
  knitr::kable(
    col.names = c(
      "City",
      "Adjusted OR (Male vs Female)",
      "Lower 95% CI",
      "Upper 95% CI"
    )
  )
```

| City               | Adjusted OR (Male vs Female) | Lower 95% CI | Upper 95% CI |
|:-------------------|-----------------------------:|-------------:|-------------:|
| New York, NY       |                        0.262 |        0.133 |        0.485 |
| Baton Rouge, LA    |                        0.381 |        0.204 |        0.684 |
| Omaha, NE          |                        0.382 |        0.199 |        0.711 |
| Cincinnati, OH     |                        0.400 |        0.231 |        0.667 |
| Chicago, IL        |                        0.410 |        0.336 |        0.501 |
| Long Beach, CA     |                        0.410 |        0.143 |        1.024 |
| San Diego, CA      |                        0.413 |        0.191 |        0.830 |
| Baltimore, MD      |                        0.426 |        0.324 |        0.558 |
| Pittsburgh, PA     |                        0.431 |        0.263 |        0.696 |
| Denver, CO         |                        0.479 |        0.233 |        0.962 |
| Louisville, KY     |                        0.491 |        0.301 |        0.784 |
| Philadelphia, PA   |                        0.496 |        0.376 |        0.650 |
| San Bernardino, CA |                        0.500 |        0.166 |        1.462 |
| Miami, FL          |                        0.515 |        0.304 |        0.873 |
| Buffalo, NY        |                        0.521 |        0.288 |        0.936 |
| Columbus, OH       |                        0.532 |        0.377 |        0.748 |
| Oakland, CA        |                        0.563 |        0.364 |        0.867 |
| Detroit, MI        |                        0.582 |        0.462 |        0.734 |
| New Orleans, LA    |                        0.585 |        0.422 |        0.812 |
| San Francisco, CA  |                        0.608 |        0.312 |        1.155 |
| Los Angeles, CA    |                        0.662 |        0.457 |        0.954 |
| Sacramento, CA     |                        0.669 |        0.326 |        1.314 |
| Fort Worth, TX     |                        0.669 |        0.394 |        1.121 |
| Boston, MA         |                        0.674 |        0.353 |        1.277 |
| Washington, DC     |                        0.690 |        0.465 |        1.012 |
| St. Louis, MO      |                        0.703 |        0.530 |        0.932 |
| San Antonio, TX    |                        0.705 |        0.393 |        1.238 |
| Houston, TX        |                        0.711 |        0.557 |        0.906 |
| Jacksonville, FL   |                        0.720 |        0.536 |        0.965 |
| Memphis, TN        |                        0.723 |        0.526 |        0.984 |
| Milwaukee, wI      |                        0.727 |        0.495 |        1.054 |
| Tampa, FL          |                        0.808 |        0.340 |        1.860 |
| Durham, NC         |                        0.812 |        0.382 |        1.658 |
| Las Vegas, NV      |                        0.837 |        0.606 |        1.151 |
| Savannah, GA       |                        0.867 |        0.419 |        1.780 |
| Birmingham, AL     |                        0.870 |        0.571 |        1.314 |
| Charlotte, NC      |                        0.884 |        0.551 |        1.391 |
| Indianapolis, IN   |                        0.919 |        0.678 |        1.241 |
| Minneapolis, MN    |                        0.947 |        0.476 |        1.881 |
| Oklahoma City, OK  |                        0.974 |        0.623 |        1.520 |
| Tulsa, OK          |                        0.976 |        0.609 |        1.544 |
| Atlanta, GA        |                        1.000 |        0.680 |        1.458 |
| Richmond, VA       |                        1.006 |        0.483 |        1.994 |
| Nashville, TN      |                        1.034 |        0.681 |        1.556 |
| Fresno, CA         |                        1.335 |        0.567 |        3.048 |
| Stockton, CA       |                        1.352 |        0.626 |        2.994 |
| Albuquerque, NM    |                        1.767 |        0.825 |        3.762 |

**Create a plot shows the estimated ORs and CIs for each city**

``` r
city_results |> 
  mutate(city_state = fct_reorder(city_state, or)) |> 
  ggplot(aes(x = city_state, y = or)) +
  geom_point(color = "red") +
  geom_errorbar(aes(ymin = or_lower, ymax = or_upper), width = 0.5) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Figure 1: Adjusted ORs for solving homicides (Male vs Female)",
    x = "City",
    y = "Adjusted OR"
  ) +
  theme_minimal()
```

![](p8105_hw6_ns3923_files/figure-gfm/P1_plot-1.png)<!-- -->

**Interpretation:** Most cities have odds ratios below 1, meaning
homicides involving male victims are less likely to be solved than those
involving female victims, after adjusting for victim age and race. Only
a few cities, such as Albuquerque, NM, Stockton, CA, and Fresno, CA,
have odds ratios above 1. Still, their confidence intervals are wide, so
the results are uncertain, and we cannot be sure whether solving rates
are truly higher among male than female victims. These uncertain
exceptions may reflect a smaller population or more variable case
patterns in those cities. The lowest odds ratios are in New York, NY,
Baton Rouge, LA, and Omaha, NE. These cities show a much lower chance of
solving cases involving male victims.

## Problem 2: Central Park weather data

**Import data**

``` r
data("weather_df")
```

The boostrap is helpful when you’d like to perform inference for a
parameter / value / summary that doesn’t have an easy-to-write-down
distribution in the usual repeated sampling framework. We’ll focus on a
simple linear regression with tmax as the response with tmin and prcp as
the predictors, and are interested in the distribution of two quantities
estimated from these data:

r^2 β<sup>1β</sup>2 Use 5000 bootstrap samples and, for each bootstrap
sample, produce estimates of these two quantities. Plot the distribution
of your estimates, and describe these in words. Using the 5000 bootstrap
estimates, identify the 2.5% and 97.5% quantiles to provide a 95%
confidence interval for r^2 and β<sup>1β</sup>2 .

Note: broom::glance() is helpful for extracting r^2 from a fitted
regression, and broom::tidy() (with some additional wrangling) should
help in computing β<sup>1β</sup>2
